{
  "file_path": "documents/enterrpise_linux_ai/Red_Hat_Enterprise_Linux_AI-1.5-Hardware_Requirements-en-US.pdf",
  "product": "enterrpise_linux_ai",
  "product_name": "Red Hat Enterprise Linux AI",
  "filename": "Red_Hat_Enterprise_Linux_AI-1.5-Hardware_Requirements-en-US.pdf",
  "content": "Red Hat Enterprise Linux AI\n \n1.5\nHardware Requirements\nHardware requirements for RHEL AI\nLast Updated: 2025-06-27\n\nRed Hat Enterprise Linux AI\n \n1.5\n \nHardware Requirements\nHardware requirements for RHEL AI\nLegal Notice\nCopyright \n©\n 2025 Red Hat, Inc.\nThe text of and illustrations in this document are licensed by Red Hat under a Creative Commons\nAttribution–Share Alike 3.0 Unported license (\"CC-BY-SA\"). An explanation of CC-BY-SA is\navailable at\nhttp://creativecommons.org/licenses/by-sa/3.0/\n. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must\nprovide the URL for the original version.\nRed Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert,\nSection 4d of CC-BY-SA to the fullest extent permitted by applicable law.\nRed Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift,\nFedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States\nand other countries.\nLinux ®\n is the registered trademark of Linus Torvalds in the United States and other countries.\nJava ®\n is a registered trademark of Oracle and/or its affiliates.\nXFS ®\n is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States\nand/or other countries.\nMySQL ®\n is a registered trademark of MySQL AB in the United States, the European Union and\nother countries.\nNode.js ®\n is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the\nofficial Joyent Node.js open source or commercial project.\nThe \nOpenStack ®\n Word Mark and OpenStack logo are either registered trademarks/service marks\nor trademarks/service marks of the OpenStack Foundation, in the United States and other\ncountries and are used with the OpenStack Foundation's permission. We are not affiliated with,\nendorsed or sponsored by the OpenStack Foundation, or the OpenStack community.\nAll other trademarks are the property of their respective owners.\nAbstract\nThis document provides details for RHEL AI hardware requirements\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nTable of Contents\nCHAPTER 1. RED HAT ENTERPRISE LINUX AI HARDWARE REQUIREMENTS\n1.1. HARDWARE REQUIREMENTS FOR END-TO-END WORKFLOW OF GRANITE MODELS\n1.1.1. Bare metal\n1.1.2. IBM Cloud\n1.1.3. Amazon Web Services (AWS)\n1.1.4. Azure\n1.1.5. Google Cloud Platform (GCP)\n1.2. HARDWARE REQUIREMENTS FOR INFERENCE SERVING GRANITE MODELS\n1.2.1. Bare metal\n1.2.2. Amazon Web Services (AWS)\n1.2.3. IBM cloud\n1.2.4. Azure\n1.2.5. Google Cloud Platform (GCP)\n3\n3\n3\n3\n4\n4\n5\n5\n5\n6\n6\n6\n7\nTable of Contents\n1\nRed Hat Enterprise Linux AI 1.5 Hardware Requirements\n2\nCHAPTER 1. RED HAT ENTERPRISE LINUX AI HARDWARE\nREQUIREMENTS\nVarious hardware accelerators require different requirements for serving and inferencing as well as\ninstalling, generating and training the Granite starter model on Red Hat Enterprise Linux AI.\n1.1. HARDWARE REQUIREMENTS FOR END-TO-END WORKFLOW OF\nGRANITE MODELS\nThe following charts show the hardware requirements for running the full InstructLab end-to-end\nworkflow to customize the Granite student model. This includes: synthetic data generation (SDG),\nmulti-phase training, and evaluating a custom Granite model.\n1.1.1. Bare metal\nHardware\nvendor\nSupported accelerators (GPUs)\nAggregate GPU memory\nRecommende\nd additional\ndisk storage\nNVIDIA\n2xA100\n4xA100\n8xA100\n160 GB\n320 GB\n640 GB\n3 TB\nNVIDIA\n2xH100\n4xH100\n8xH100\n160 GB\n320 GB\n640 GB\n3 TB\nNVIDIA\n2xH200\n4xH200\n8xH200\n282 GB\n564 GB\n1128 GB\n3 TB\nNVIDIA\n4xL40S\n8xL40S\n192 GB\n384 GB\n3 TB\nAMD\n2xMI300X\n4xMI300X\n8xMI300X\n384 GB\n768 GB\n1536 GB\n3 TB\n1.1.2. IBM Cloud\nCHAPTER 1. RED HAT ENTERPRISE LINUX AI HARDWARE REQUIREMENTS\n3\nHardware\nvendor\nSupported accelerators\n(GPUs)\nAggregate GPU\nMemory\nIBM Cloud Instances\nRecomme\nnded\nadditional\ndisk\nstorage\nNVIDIA\n2xA100\n160 GB\ngx3d-48x240x2a100p\n3 TB\nNVIDIA\n8xH100\n640 GB\ngx3d-160x1792x8h100\n3 TB\nNVIDIA\n8xH200\n1128 GB\ngx3d-160x1792x8h200\n3 TB\nAMD\n8xMI300X\n1536 GB\ngx3d-\n208x1792x8mi300x\n3 TB\n1.1.3. Amazon Web Services (AWS)\nHardware\nvendor\nSupported accelerators\n(GPUs)\nAggregate GPU\nMemory\nAWS Instances\nRecomme\nnded\nadditional\ndisk\nstorage\nNVIDIA\n8xA100\n320 GB\np4d.24xlarge\n3 TB\nNVIDIA\n8xA100\n640 GB\np4de.24xlarge\n3 TB\nNVIDIA\n8xH100\n640 GB\np5.48xlarge\n3 TB\nNVIDIA\n8xL40S\n384 GB\ng6e.48xlarge\n3 TB\n1.1.4. Azure\nHardware\nvendor\nSupported accelerators\n(GPUs)\nAggregate GPU\nMemory\nAzure Instances\nRecomme\nnded\nadditional\ndisk\nstorage\nNVIDIA\n8xA100\n640 GB\nStandard_ND96amsr_A\n100_v4\n3 TB\nNVIDIA\n4xA100\n320 GB\nStandard_ND96asr_A10\n0_v4\n3 TB\nNVIDIA\n8xH100\n640 GB\nStandard_ND96isr_H10\n0_v5\n3 TB\nRed Hat Enterprise Linux AI 1.5 Hardware Requirements\n4\nAMD\n8xMI300X\n1535 GB\nStandard_ND96is_MI30\n0X_v5\n3 TB\nHardware\nvendor\nSupported accelerators\n(GPUs)\nAggregate GPU\nMemory\nAzure Instances\nRecomme\nnded\nadditional\ndisk\nstorage\n1.1.5. Google Cloud Platform (GCP)\nHardware\nvendor\nSupported accelerators\n(GPUs)\nAggregate GPU\nMemory\nGCP Instances\nRecomme\nnded\nadditional\ndisk\nstorage\nNVIDIA\n8xA100\n640 GB\na2-highgpu-8g\n3 TB\nNVIDIA\n8xH100\n640 GB\na3-highgpu-8g\na3-megagpu-8g\n3 TB\n1.2. HARDWARE REQUIREMENTS FOR INFERENCE SERVING GRANITE\nMODELS\nThe following charts display the minimum hardware requirements for inference serving a model on Red\nHat Enterprise Linux AI.\n1.2.1. Bare metal\nHardware vendor\nSupported accelerators\n(GPUs)\nMinimum Aggregate\nGPU memory\nRecommended\nadditional disk storage\nNVIDIA\nA100\n80 GB\n1 TB\nNVIDIA\nH100\n80 GB\n1 TB\nNVIDIA\nH200\n141 GB\n1 TB\nNVIDIA\nGH200 (Technology\nPreview)\n192 GB\n1 TP\nNVIDIA\nL40S\n48 GB\n1 TB\nNVIDIA\nL4\n24 GB\n1 TB\nCHAPTER 1. RED HAT ENTERPRISE LINUX AI HARDWARE REQUIREMENTS\n5\nAMD\nMI300X\n192 GB\n1 TB\nIntel\nGaudi 3 (Technology\nPreview)\n128 GB\n1 TB\nHardware vendor\nSupported accelerators\n(GPUs)\nMinimum Aggregate\nGPU memory\nRecommended\nadditional disk storage\n1.2.2. Amazon Web Services (AWS)\nHardware vendor\nSupported\naccelerators\n(GPUs)\nMinimum\nAggregate GPU\nMemory\nAWS Instance\nfamily\nRecommended\nadditional disk\nstorage\nNVIDIA\nA100\n40 GB\nP4d series\n1 TB\nNVIDIA\nH100\n80 GB\nP5 series\n1 TB\nNVIDIA\nL40S\n48 GB\nG6e series\n1 TB\nNVIDIA\nL4\n24 GB\nG6 series\n1 TB\n1.2.3. IBM cloud\nHardware vendor\nSupported\naccelerators\n(GPUs)\nMinimum\nAggregate GPU\nMemory\nIBM Cloud\nInstance family\nRecommended\nadditional disk\nstorage\nNVIDIA\nL4\n24 GB\ngx3 series\n1 TB\nNVIDIA\nL40S\n48 GB\ngx3 series\n1 TB\nNVIDIA\nA100\n80 GB\ngx3 series\n1 TB\nNVIDIA\nH100\n80 GB\ngx3 series\n1 TB\nNVIDIA\nH200\n141 GB\ngx3 series\n1 TB\nAMD\nMI300X\n192 GB\ngx3 series\n1 TB\nIntel\nGaudi 3\n(Technology\nPreview)\n128 GB\ngx3 series\n1 TB\n1.2.4. Azure\nRed Hat Enterprise Linux AI 1.5 Hardware Requirements\n6\nHardware vendor\nSupported\naccelerators\n(GPUs)\nMinimum\nAggregate GPU\nMemory\nAzure Instance\nfamily\nRecommended\nadditional disk\nstorage\nNVIDIA\nA100\n80 GB\nND series\n1 TB\nNVIDIA\nH100\n80 GB\nND sereis\n1 TB\nAMD\nMI300X\n192 GB\nND series\n1 TB\n1.2.5. Google Cloud Platform (GCP)\nHardware vendor\nSupported\naccelerators\n(GPUs)\nMinimum\nAggregate GPU\nMemory\nGCP Instance\nfamily\nRecommended\nadditional disk\nstorage\nNVIDIA\nA100\n40 GB\nA2 series\n1 TB\nNVIDIA\nH100\n80 GB\nA3 series\n1 TB\nNVIDIA\n4xL4\n96 GB\nG2 series\n1 TB\nCHAPTER 1. RED HAT ENTERPRISE LINUX AI HARDWARE REQUIREMENTS\n7\n",
  "metadata": {
    "filename": "Red_Hat_Enterprise_Linux_AI-1.5-Hardware_Requirements-en-US.pdf",
    "format": "text",
    "processed_at": "2025-07-29T00:20:45.596664",
    "pages": 11,
    "method": "PyPDF2_fallback"
  },
  "processed_at": "2025-07-29T00:20:45.596733",
  "success": true
}